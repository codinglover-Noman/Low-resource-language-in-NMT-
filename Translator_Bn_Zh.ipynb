{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/codinglover-Noman/Low-resource-language-in-NMT-/blob/main/Translator_Bn_Zh.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e6dcfc6",
      "metadata": {
        "id": "2e6dcfc6"
      },
      "outputs": [],
      "source": [
        "# !pip install transformers sentencepiece datasets\n",
        "# !pip install ipython\n",
        "\n",
        "from datasets import load_dataset\n",
        "# from google.colab import drive\n",
        "from IPython.display import display\n",
        "# from IPython.html import widgets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import torch\n",
        "from torch import optim\n",
        "from torch.nn import functional as F\n",
        "from transformers import AdamW, AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from tqdm import tqdm_notebook\n",
        "\n",
        "sns.set()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ce2afe2",
      "metadata": {
        "id": "4ce2afe2"
      },
      "outputs": [],
      "source": [
        "model_repo = \"google/mt5-small\"\n",
        "# model_path = \"mt5_translation.pt\"\n",
        "max_seq_len = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9e1afe2",
      "metadata": {
        "id": "b9e1afe2",
        "outputId": "1b5c0567-e8e6-416e-d013-93521fce24b1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\MSI\\anaconda3\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:446: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_repo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9a72952",
      "metadata": {
        "id": "c9a72952"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_repo)\n",
        "model = model.cpu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c60af8e5",
      "metadata": {
        "id": "c60af8e5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb303c8c",
      "metadata": {
        "id": "cb303c8c",
        "outputId": "e67ba4d3-bf26-4ff5-bb56-da6d418f416a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[  1494,    898,    390,  37194,    285,    288,  30865,    309,    274,\n",
            "         116024,  11994,    271,      1]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\MSI\\anaconda3\\lib\\site-packages\\transformers\\generation_utils.py:1359: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 20 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[     0, 250099,      1]])\n",
            "<pad> <extra_id_0></s>\n"
          ]
        }
      ],
      "source": [
        "token_ids = tokenizer.encode(\n",
        "    ' This will be translated to Japanese! (hopefully)',\n",
        "    return_tensors='pt').cpu()\n",
        "print(token_ids)\n",
        "\n",
        "model_out = model.generate(token_ids)\n",
        "print(model_out)\n",
        "\n",
        "output_text = tokenizer.convert_tokens_to_string(\n",
        "    tokenizer.convert_ids_to_tokens(model_out[0]))\n",
        "print(output_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c193b104",
      "metadata": {
        "id": "c193b104",
        "outputId": "c40bf56c-8fda-4169-f9a0-b35ea0f31ab4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input IDs: tensor([[1494,  339, 1627,  259,  262, 2978,  259,  272, 1982, 1315,  260,    1]])\n",
            "Tokens: ['▁This', '▁is', '▁just', '▁', 'a', '▁test', '▁', 'n', 'bu', 'ig', '.', '</s>']\n"
          ]
        }
      ],
      "source": [
        "example_input_str = ' This is just a test nbuig.'\n",
        "# example_input_str = 'これは普通のテスト'\n",
        "input_ids = tokenizer.encode(example_input_str, return_tensors='pt')\n",
        "print('Input IDs:', input_ids)\n",
        "\n",
        "tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
        "print('Tokens:', tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d31d98b",
      "metadata": {
        "id": "4d31d98b",
        "outputId": "0ca2aae7-8a76-486a-e16b-3321e6421627"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('<pad>', 0),\n",
              " ('</s>', 1),\n",
              " ('<unk>', 2),\n",
              " ('<0x00>', 3),\n",
              " ('<0x01>', 4),\n",
              " ('<0x02>', 5),\n",
              " ('<0x03>', 6),\n",
              " ('<0x04>', 7),\n",
              " ('<0x05>', 8),\n",
              " ('<0x06>', 9),\n",
              " ('<0x07>', 10),\n",
              " ('<0x08>', 11),\n",
              " ('<0x09>', 12),\n",
              " ('<0x0A>', 13),\n",
              " ('<0x0B>', 14),\n",
              " ('<0x0C>', 15),\n",
              " ('<0x0D>', 16),\n",
              " ('<0x0E>', 17),\n",
              " ('<0x0F>', 18),\n",
              " ('<0x10>', 19),\n",
              " ('<0x11>', 20),\n",
              " ('<0x12>', 21),\n",
              " ('<0x13>', 22),\n",
              " ('<0x14>', 23),\n",
              " ('<0x15>', 24),\n",
              " ('<0x16>', 25),\n",
              " ('<0x17>', 26),\n",
              " ('<0x18>', 27),\n",
              " ('<0x19>', 28),\n",
              " ('<0x1A>', 29),\n",
              " ('<0x1B>', 30),\n",
              " ('<0x1C>', 31),\n",
              " ('<0x1D>', 32),\n",
              " ('<0x1E>', 33),\n",
              " ('<0x1F>', 34),\n",
              " ('<0x20>', 35),\n",
              " ('<0x21>', 36),\n",
              " ('<0x22>', 37),\n",
              " ('<0x23>', 38),\n",
              " ('<0x24>', 39),\n",
              " ('<0x25>', 40),\n",
              " ('<0x26>', 41),\n",
              " ('<0x27>', 42),\n",
              " ('<0x28>', 43),\n",
              " ('<0x29>', 44),\n",
              " ('<0x2A>', 45),\n",
              " ('<0x2B>', 46),\n",
              " ('<0x2C>', 47),\n",
              " ('<0x2D>', 48),\n",
              " ('<0x2E>', 49),\n",
              " ('<0x2F>', 50),\n",
              " ('<0x30>', 51),\n",
              " ('<0x31>', 52),\n",
              " ('<0x32>', 53),\n",
              " ('<0x33>', 54),\n",
              " ('<0x34>', 55),\n",
              " ('<0x35>', 56),\n",
              " ('<0x36>', 57),\n",
              " ('<0x37>', 58),\n",
              " ('<0x38>', 59),\n",
              " ('<0x39>', 60),\n",
              " ('<0x3A>', 61),\n",
              " ('<0x3B>', 62),\n",
              " ('<0x3C>', 63),\n",
              " ('<0x3D>', 64),\n",
              " ('<0x3E>', 65),\n",
              " ('<0x3F>', 66),\n",
              " ('<0x40>', 67),\n",
              " ('<0x41>', 68),\n",
              " ('<0x42>', 69),\n",
              " ('<0x43>', 70),\n",
              " ('<0x44>', 71),\n",
              " ('<0x45>', 72),\n",
              " ('<0x46>', 73),\n",
              " ('<0x47>', 74),\n",
              " ('<0x48>', 75),\n",
              " ('<0x49>', 76),\n",
              " ('<0x4A>', 77),\n",
              " ('<0x4B>', 78),\n",
              " ('<0x4C>', 79),\n",
              " ('<0x4D>', 80),\n",
              " ('<0x4E>', 81),\n",
              " ('<0x4F>', 82),\n",
              " ('<0x50>', 83),\n",
              " ('<0x51>', 84),\n",
              " ('<0x52>', 85),\n",
              " ('<0x53>', 86),\n",
              " ('<0x54>', 87),\n",
              " ('<0x55>', 88),\n",
              " ('<0x56>', 89),\n",
              " ('<0x57>', 90),\n",
              " ('<0x58>', 91),\n",
              " ('<0x59>', 92),\n",
              " ('<0x5A>', 93),\n",
              " ('<0x5B>', 94),\n",
              " ('<0x5C>', 95),\n",
              " ('<0x5D>', 96),\n",
              " ('<0x5E>', 97),\n",
              " ('<0x5F>', 98),\n",
              " ('<0x60>', 99),\n",
              " ('<0x61>', 100),\n",
              " ('<0x62>', 101),\n",
              " ('<0x63>', 102),\n",
              " ('<0x64>', 103),\n",
              " ('<0x65>', 104),\n",
              " ('<0x66>', 105),\n",
              " ('<0x67>', 106),\n",
              " ('<0x68>', 107),\n",
              " ('<0x69>', 108),\n",
              " ('<0x6A>', 109),\n",
              " ('<0x6B>', 110),\n",
              " ('<0x6C>', 111),\n",
              " ('<0x6D>', 112),\n",
              " ('<0x6E>', 113),\n",
              " ('<0x6F>', 114),\n",
              " ('<0x70>', 115),\n",
              " ('<0x71>', 116),\n",
              " ('<0x72>', 117),\n",
              " ('<0x73>', 118),\n",
              " ('<0x74>', 119),\n",
              " ('<0x75>', 120),\n",
              " ('<0x76>', 121),\n",
              " ('<0x77>', 122),\n",
              " ('<0x78>', 123),\n",
              " ('<0x79>', 124),\n",
              " ('<0x7A>', 125),\n",
              " ('<0x7B>', 126),\n",
              " ('<0x7C>', 127),\n",
              " ('<0x7D>', 128),\n",
              " ('<0x7E>', 129),\n",
              " ('<0x7F>', 130),\n",
              " ('<0x80>', 131),\n",
              " ('<0x81>', 132),\n",
              " ('<0x82>', 133),\n",
              " ('<0x83>', 134),\n",
              " ('<0x84>', 135),\n",
              " ('<0x85>', 136),\n",
              " ('<0x86>', 137),\n",
              " ('<0x87>', 138),\n",
              " ('<0x88>', 139),\n",
              " ('<0x89>', 140),\n",
              " ('<0x8A>', 141),\n",
              " ('<0x8B>', 142),\n",
              " ('<0x8C>', 143),\n",
              " ('<0x8D>', 144),\n",
              " ('<0x8E>', 145),\n",
              " ('<0x8F>', 146),\n",
              " ('<0x90>', 147),\n",
              " ('<0x91>', 148),\n",
              " ('<0x92>', 149),\n",
              " ('<0x93>', 150),\n",
              " ('<0x94>', 151),\n",
              " ('<0x95>', 152),\n",
              " ('<0x96>', 153),\n",
              " ('<0x97>', 154),\n",
              " ('<0x98>', 155),\n",
              " ('<0x99>', 156),\n",
              " ('<0x9A>', 157),\n",
              " ('<0x9B>', 158),\n",
              " ('<0x9C>', 159),\n",
              " ('<0x9D>', 160),\n",
              " ('<0x9E>', 161),\n",
              " ('<0x9F>', 162),\n",
              " ('<0xA0>', 163),\n",
              " ('<0xA1>', 164),\n",
              " ('<0xA2>', 165),\n",
              " ('<0xA3>', 166),\n",
              " ('<0xA4>', 167),\n",
              " ('<0xA5>', 168),\n",
              " ('<0xA6>', 169),\n",
              " ('<0xA7>', 170),\n",
              " ('<0xA8>', 171),\n",
              " ('<0xA9>', 172),\n",
              " ('<0xAA>', 173),\n",
              " ('<0xAB>', 174),\n",
              " ('<0xAC>', 175),\n",
              " ('<0xAD>', 176),\n",
              " ('<0xAE>', 177),\n",
              " ('<0xAF>', 178),\n",
              " ('<0xB0>', 179),\n",
              " ('<0xB1>', 180),\n",
              " ('<0xB2>', 181),\n",
              " ('<0xB3>', 182),\n",
              " ('<0xB4>', 183),\n",
              " ('<0xB5>', 184),\n",
              " ('<0xB6>', 185),\n",
              " ('<0xB7>', 186),\n",
              " ('<0xB8>', 187),\n",
              " ('<0xB9>', 188),\n",
              " ('<0xBA>', 189),\n",
              " ('<0xBB>', 190),\n",
              " ('<0xBC>', 191),\n",
              " ('<0xBD>', 192),\n",
              " ('<0xBE>', 193),\n",
              " ('<0xBF>', 194),\n",
              " ('<0xC0>', 195),\n",
              " ('<0xC1>', 196),\n",
              " ('<0xC2>', 197),\n",
              " ('<0xC3>', 198),\n",
              " ('<0xC4>', 199),\n",
              " ('<0xC5>', 200),\n",
              " ('<0xC6>', 201),\n",
              " ('<0xC7>', 202),\n",
              " ('<0xC8>', 203),\n",
              " ('<0xC9>', 204),\n",
              " ('<0xCA>', 205),\n",
              " ('<0xCB>', 206),\n",
              " ('<0xCC>', 207),\n",
              " ('<0xCD>', 208),\n",
              " ('<0xCE>', 209),\n",
              " ('<0xCF>', 210),\n",
              " ('<0xD0>', 211),\n",
              " ('<0xD1>', 212),\n",
              " ('<0xD2>', 213),\n",
              " ('<0xD3>', 214),\n",
              " ('<0xD4>', 215),\n",
              " ('<0xD5>', 216),\n",
              " ('<0xD6>', 217),\n",
              " ('<0xD7>', 218),\n",
              " ('<0xD8>', 219),\n",
              " ('<0xD9>', 220),\n",
              " ('<0xDA>', 221),\n",
              " ('<0xDB>', 222),\n",
              " ('<0xDC>', 223),\n",
              " ('<0xDD>', 224),\n",
              " ('<0xDE>', 225),\n",
              " ('<0xDF>', 226),\n",
              " ('<0xE0>', 227),\n",
              " ('<0xE1>', 228),\n",
              " ('<0xE2>', 229),\n",
              " ('<0xE3>', 230),\n",
              " ('<0xE4>', 231),\n",
              " ('<0xE5>', 232),\n",
              " ('<0xE6>', 233),\n",
              " ('<0xE7>', 234),\n",
              " ('<0xE8>', 235),\n",
              " ('<0xE9>', 236),\n",
              " ('<0xEA>', 237),\n",
              " ('<0xEB>', 238),\n",
              " ('<0xEC>', 239),\n",
              " ('<0xED>', 240),\n",
              " ('<0xEE>', 241),\n",
              " ('<0xEF>', 242),\n",
              " ('<0xF0>', 243),\n",
              " ('<0xF1>', 244),\n",
              " ('<0xF2>', 245),\n",
              " ('<0xF3>', 246),\n",
              " ('<0xF4>', 247),\n",
              " ('<0xF5>', 248),\n",
              " ('<0xF6>', 249),\n",
              " ('<0xF7>', 250),\n",
              " ('<0xF8>', 251),\n",
              " ('<0xF9>', 252),\n",
              " ('<0xFA>', 253),\n",
              " ('<0xFB>', 254),\n",
              " ('<0xFC>', 255),\n",
              " ('<0xFD>', 256),\n",
              " ('<0xFE>', 257),\n",
              " ('<0xFF>', 258),\n",
              " ('▁', 259),\n",
              " ('.', 260),\n",
              " (',', 261),\n",
              " ('a', 262),\n",
              " ('s', 263),\n",
              " ('-', 264),\n",
              " ('e', 265),\n",
              " ('i', 266),\n",
              " (':', 267),\n",
              " ('o', 268),\n",
              " ('▁de', 269),\n",
              " ('t', 270),\n",
              " (')', 271),\n",
              " ('n', 272),\n",
              " ('u', 273),\n",
              " ('▁(', 274),\n",
              " ('/', 275),\n",
              " ('y', 276),\n",
              " (\"'\", 277),\n",
              " ('en', 278),\n",
              " ('и', 279),\n",
              " ('l', 280),\n",
              " ('▁in', 281),\n",
              " ('m', 282),\n",
              " ('▁la', 283),\n",
              " ('com', 284),\n",
              " ('d', 285),\n",
              " ('r', 286),\n",
              " ('▁the', 287),\n",
              " ('▁to', 288),\n",
              " ('▁en', 289),\n",
              " ('_', 290),\n",
              " ('?', 291),\n",
              " ('、', 292),\n",
              " ('’', 293),\n",
              " ('▁na', 294),\n",
              " ('er', 295),\n",
              " (';', 296),\n",
              " ('c', 297),\n",
              " ('▁A', 298),\n",
              " ('es', 299),\n",
              " ('▁v', 300),\n",
              " ('▁di', 301),\n",
              " ('...', 302),\n",
              " ('▁se', 303),\n",
              " ('▁of', 304),\n",
              " ('▁and', 305),\n",
              " ('。', 306),\n",
              " ('▁|', 307),\n",
              " ('а', 308),\n",
              " ('!', 309),\n",
              " ('▁на', 310),\n",
              " ('\"', 311),\n",
              " ('(', 312),\n",
              " ('▁\"', 313),\n",
              " ('k', 314),\n",
              " ('▁в', 315),\n",
              " ('b', 316),\n",
              " ('▁c', 317),\n",
              " ('g', 318),\n",
              " ('▁que', 319),\n",
              " ('▁S', 320),\n",
              " ('an', 321),\n",
              " ('▁–', 322),\n",
              " ('▁www', 323),\n",
              " ('е', 324),\n",
              " ('p', 325),\n",
              " ('▁m', 326),\n",
              " ('▁sa', 327),\n",
              " ('3', 328),\n",
              " ('x', 329),\n",
              " ('▁b', 330),\n",
              " ('▁d', 331),\n",
              " ('▁for', 332),\n",
              " ('▁1', 333),\n",
              " ('h', 334),\n",
              " ('▁un', 335),\n",
              " ('▁I', 336),\n",
              " ('os', 337),\n",
              " ('2', 338),\n",
              " ('▁is', 339),\n",
              " ('▁le', 340),\n",
              " ('▁و', 341),\n",
              " ('▁do', 342),\n",
              " ('،', 343),\n",
              " ('▁at', 344),\n",
              " ('ed', 345),\n",
              " ('te', 346),\n",
              " ('ing', 347),\n",
              " ('in', 348),\n",
              " ('=', 349),\n",
              " ('▁da', 350),\n",
              " ('▁on', 351),\n",
              " ('▁M', 352),\n",
              " ('1', 353),\n",
              " ('у', 354),\n",
              " ('▁đ', 355),\n",
              " ('▁2', 356),\n",
              " ('A', 357),\n",
              " ('as', 358),\n",
              " ('▁“', 359),\n",
              " ('z', 360),\n",
              " ('é', 361),\n",
              " ('▁el', 362),\n",
              " ('▁P', 363),\n",
              " ('▁B', 364),\n",
              " ('”', 365),\n",
              " ('▁T', 366),\n",
              " ('f', 367),\n",
              " ('de', 368),\n",
              " ('à', 369),\n",
              " ('ng', 370),\n",
              " ('▁C', 371),\n",
              " ('ar', 372),\n",
              " ('▁og', 373),\n",
              " ('▁за', 374),\n",
              " ('▁no', 375),\n",
              " ('ه', 376),\n",
              " ('na', 377),\n",
              " ('।', 378),\n",
              " ('v', 379),\n",
              " ('re', 380),\n",
              " ('▁3', 381),\n",
              " ('▁h', 382),\n",
              " ('▁et', 383),\n",
              " ('▁je', 384),\n",
              " ('j', 385),\n",
              " ('▁il', 386),\n",
              " ('▁#', 387),\n",
              " ('▁с', 388),\n",
              " ('і', 389),\n",
              " ('▁be', 390),\n",
              " ('://', 391),\n",
              " ('▁2018', 392),\n",
              " ('▁per', 393),\n",
              " ('▁th', 394),\n",
              " ('▁si', 395),\n",
              " ('я', 396),\n",
              " ('▁z', 397),\n",
              " ('▁die', 398),\n",
              " ('S', 399),\n",
              " ('▁te', 400),\n",
              " ('▁не', 401),\n",
              " ('▁ال', 402),\n",
              " ('D', 403),\n",
              " ('▁«', 404),\n",
              " ('ne', 405),\n",
              " ('ی', 406),\n",
              " ('da', 407),\n",
              " ('▁k', 408),\n",
              " ('|', 409),\n",
              " ('4', 410),\n",
              " ('о', 411),\n",
              " ('▁K', 412),\n",
              " ('▁du', 413),\n",
              " ('▁w', 414),\n",
              " ('▁E', 415),\n",
              " ('▁me', 416),\n",
              " ('is', 417),\n",
              " ('▁are', 418),\n",
              " ('▁4', 419),\n",
              " ('í', 420),\n",
              " ('▁p', 421),\n",
              " ('ta', 422),\n",
              " ('の', 423),\n",
              " ('C', 424),\n",
              " ('▁по', 425),\n",
              " ('▁del', 426),\n",
              " ('▁ka', 427),\n",
              " ('5', 428),\n",
              " ('et', 429),\n",
              " ('▁5', 430),\n",
              " ('▁D', 431),\n",
              " ('▁ja', 432),\n",
              " ('ы', 433),\n",
              " ('▁V', 434),\n",
              " ('▁para', 435),\n",
              " ('»', 436),\n",
              " ('\",\"', 437),\n",
              " ('us', 438),\n",
              " (']', 439),\n",
              " ('▁al', 440),\n",
              " ('▁N', 441),\n",
              " ('▁der', 442),\n",
              " ('▁O', 443),\n",
              " ('on', 444),\n",
              " ('ة', 445),\n",
              " ('▁да', 446),\n",
              " ('▁H', 447),\n",
              " ('▁ne', 448),\n",
              " ('8', 449),\n",
              " ('▁con', 450),\n",
              " ('6', 451),\n",
              " ('B', 452),\n",
              " ('▁er', 453),\n",
              " ('ul', 454),\n",
              " ('▁by', 455),\n",
              " ('▁у', 456),\n",
              " ('▁yang', 457),\n",
              " ('▁L', 458),\n",
              " ('▁De', 459),\n",
              " ('0', 460),\n",
              " ('▁an', 461),\n",
              " ('ja', 462),\n",
              " ('\\xad', 463),\n",
              " ('▁van', 464),\n",
              " ('▁ה', 465),\n",
              " ('▁za', 466),\n",
              " ('】【', 467),\n",
              " ('le', 468),\n",
              " ('▁dan', 469),\n",
              " ('em', 470),\n",
              " ('á', 471),\n",
              " ('▁und', 472),\n",
              " ('al', 473),\n",
              " ('è', 474),\n",
              " ('▁10', 475),\n",
              " ('to', 476),\n",
              " ('ي', 477),\n",
              " ('E', 478),\n",
              " ('ka', 479),\n",
              " ('▁...', 480),\n",
              " ('w', 481),\n",
              " ('▁på', 482),\n",
              " (').', 483),\n",
              " ('ly', 484),\n",
              " ('▁po', 485),\n",
              " ('▁The', 486),\n",
              " ('7', 487),\n",
              " ('\":\"', 488),\n",
              " ('▁G', 489),\n",
              " ('T', 490),\n",
              " ('▁[', 491),\n",
              " ('la', 492),\n",
              " ('的', 493),\n",
              " ('li', 494),\n",
              " ('9', 495),\n",
              " ('▁ma', 496),\n",
              " ('▁0', 497),\n",
              " ('▁des', 498),\n",
              " ('▁med', 499),\n",
              " ('▁til', 500),\n",
              " ('▁La', 501),\n",
              " ('kan', 502),\n",
              " ('it', 503),\n",
              " ('▁ki', 504),\n",
              " ('no', 505),\n",
              " ('),', 506),\n",
              " ('м', 507),\n",
              " ('َ', 508),\n",
              " ('▁در', 509),\n",
              " ('▁so', 510),\n",
              " ('M', 511),\n",
              " ('▁som', 512),\n",
              " ('▁ke', 513),\n",
              " ('▁with', 514),\n",
              " ('▁F', 515),\n",
              " ('ni', 516),\n",
              " ('▁su', 517),\n",
              " ('▁και', 518),\n",
              " ('▁por', 519),\n",
              " ('▁les', 520),\n",
              " ('▁you', 521),\n",
              " ('si', 522),\n",
              " ('at', 523),\n",
              " ('ti', 524),\n",
              " ('id', 525),\n",
              " ('▁av', 526),\n",
              " ('▁as', 527),\n",
              " ('▁ya', 528),\n",
              " ('▁ve', 529),\n",
              " ('▁den', 530),\n",
              " ('▁R', 531),\n",
              " ('▁ב', 532),\n",
              " ('▁that', 533),\n",
              " ('▁tr', 534),\n",
              " ('は', 535),\n",
              " ('が', 536),\n",
              " ('do', 537),\n",
              " ('N', 538),\n",
              " ('ia', 539),\n",
              " ('\\\\', 540),\n",
              " ('ce', 541),\n",
              " ('▁om', 542),\n",
              " ('й', 543),\n",
              " ('▁се', 544),\n",
              " ('F', 545),\n",
              " ('&', 546),\n",
              " ('L', 547),\n",
              " ('▁م', 548),\n",
              " ('▁&', 549),\n",
              " ('▁د', 550),\n",
              " ('▁det', 551),\n",
              " ('▁от', 552),\n",
              " ('ó', 553),\n",
              " ('▁به', 554),\n",
              " ('▁pa', 555),\n",
              " ('▁من', 556),\n",
              " ('K', 557),\n",
              " ('на', 558),\n",
              " ('P', 559),\n",
              " ('▁ha', 560),\n",
              " ('V', 561),\n",
              " ('▁ch', 562),\n",
              " ('▁In', 563),\n",
              " ('▁W', 564),\n",
              " ('▁„', 565),\n",
              " ('I', 566),\n",
              " ('▁var', 567),\n",
              " ('▁ni', 568),\n",
              " ('se', 569),\n",
              " ('▁6', 570),\n",
              " ('ra', 571),\n",
              " ('ل', 572),\n",
              " ('▁una', 573),\n",
              " ('を', 574),\n",
              " ('▁في', 575),\n",
              " ('▁ta', 576),\n",
              " ('▁http', 577),\n",
              " ('COM', 578),\n",
              " ('am', 579),\n",
              " ('ה', 580),\n",
              " ('▁U', 581),\n",
              " ('R', 582),\n",
              " ('▁з', 583),\n",
              " ('▁re', 584),\n",
              " ('▁op', 585),\n",
              " ('ن', 586),\n",
              " ('т', 587),\n",
              " ('▁har', 588),\n",
              " ('ο', 589),\n",
              " ('H', 590),\n",
              " ('“', 591),\n",
              " ('ek', 592),\n",
              " ('▁ag', 593),\n",
              " ('▁ng', 594),\n",
              " ('▁los', 595),\n",
              " ('{', 596),\n",
              " ('▁och', 597),\n",
              " ('▁2017', 598),\n",
              " ('▁WWW', 599),\n",
              " ('に', 600),\n",
              " ('▁ku', 601),\n",
              " ('ir', 602),\n",
              " ('▁pe', 603),\n",
              " ('un', 604),\n",
              " ('х', 605),\n",
              " ('um', 606),\n",
              " ('▁2019', 607),\n",
              " ('je', 608),\n",
              " ('▁it', 609),\n",
              " ('▁до', 610),\n",
              " ('을', 611),\n",
              " ('ʻ', 612),\n",
              " ('www', 613),\n",
              " ('▁ب', 614),\n",
              " ('▁li', 615),\n",
              " ('но', 616),\n",
              " ('▁7', 617),\n",
              " ('▁»', 618),\n",
              " ('▁ir', 619),\n",
              " ('▁kan', 620),\n",
              " ('G', 621),\n",
              " ('▁het', 622),\n",
              " ('▁ho', 623),\n",
              " ('▁par', 624),\n",
              " ('▁vi', 625),\n",
              " ('・', 626),\n",
              " ('で', 627),\n",
              " ('▁20', 628),\n",
              " ('▁të', 629),\n",
              " ('▁8', 630),\n",
              " ('▁or', 631),\n",
              " ('ا', 632),\n",
              " ('م', 633),\n",
              " ('ie', 634),\n",
              " ('▁В', 635),\n",
              " ('ت', 636),\n",
              " ('ом', 637),\n",
              " ('W', 638),\n",
              " ('▁was', 639),\n",
              " ('την', 640),\n",
              " ('▁के', 641),\n",
              " ('▁En', 642),\n",
              " ('▁af', 643),\n",
              " ('▁12', 644),\n",
              " ('me', 645),\n",
              " ('O', 646),\n",
              " ('nya', 647),\n",
              " ('ma', 648),\n",
              " ('의', 649),\n",
              " ('ki', 650),\n",
              " ('▁cu', 651),\n",
              " ('μ', 652),\n",
              " ('▁No', 653),\n",
              " ('▁2016', 654),\n",
              " ('▁es', 655),\n",
              " ('▁een', 656),\n",
              " ('ки', 657),\n",
              " ('▁mi', 658),\n",
              " ('Ð', 659),\n",
              " ('10', 660),\n",
              " ('▁—', 661),\n",
              " ('ku', 662),\n",
              " ('\":', 663),\n",
              " ('▁J', 664),\n",
              " ('px', 665),\n",
              " ('일', 666),\n",
              " ('▁ל', 667),\n",
              " ('ни', 668),\n",
              " ('>', 669),\n",
              " ('▁15', 670),\n",
              " ('▁‘', 671),\n",
              " ('▁ver', 672),\n",
              " ('▁um', 673),\n",
              " ('▁man', 674),\n",
              " ('▁ko', 675),\n",
              " ('+', 676),\n",
              " ('▁nh', 677),\n",
              " ('η', 678),\n",
              " ('ка', 679),\n",
              " ('ny', 680),\n",
              " ('α', 681),\n",
              " ('▁od', 682),\n",
              " ('▁wa', 683),\n",
              " ('▁ge', 684),\n",
              " ('ов', 685),\n",
              " ('н', 686),\n",
              " ('ten', 687),\n",
              " ('▁С', 688),\n",
              " ('▁מ', 689),\n",
              " ('▁ph', 690),\n",
              " ('▁>', 691),\n",
              " ('▁men', 692),\n",
              " ('▁ber', 693),\n",
              " ('▁του', 694),\n",
              " ('▁از', 695),\n",
              " ('il', 696),\n",
              " ('ch', 697),\n",
              " ('▁bir', 698),\n",
              " ('▁το', 699),\n",
              " ('▁να', 700),\n",
              " ('el', 701),\n",
              " ('▁from', 702),\n",
              " ('▁nu', 703),\n",
              " ('ko', 704),\n",
              " ('st', 705),\n",
              " ('ë', 706),\n",
              " ('▁lo', 707),\n",
              " ('ủ', 708),\n",
              " ('▁az', 709),\n",
              " ('▁dem', 710),\n",
              " ('mi', 711),\n",
              " ('▁va', 712),\n",
              " ('▁att', 713),\n",
              " ('▁this', 714),\n",
              " ('ur', 715),\n",
              " ('▁nie', 716),\n",
              " ('#', 717),\n",
              " ('▁gi', 718),\n",
              " ('▁tu', 719),\n",
              " ('di', 720),\n",
              " ('å', 721),\n",
              " ('ات', 722),\n",
              " ('or', 723),\n",
              " ('▁em', 724),\n",
              " ('と', 725),\n",
              " ('ת', 726),\n",
              " ('▁Na', 727),\n",
              " ('▁am', 728),\n",
              " ('▁из', 729),\n",
              " ('▁11', 730),\n",
              " ('▁pro', 731),\n",
              " ('▁în', 732),\n",
              " ('▁30', 733),\n",
              " ('▁che', 734),\n",
              " ('для', 735),\n",
              " ('▁Z', 736),\n",
              " ('ru', 737),\n",
              " ('▁can', 738),\n",
              " ('ya', 739),\n",
              " ('▁ang', 740),\n",
              " ('ai', 741),\n",
              " ('▁f', 742),\n",
              " ('ga', 743),\n",
              " ('▁+', 744),\n",
              " ('za', 745),\n",
              " ('▁Se', 746),\n",
              " ('이', 747),\n",
              " ('ю', 748),\n",
              " ('▁mit', 749),\n",
              " ('ca', 750),\n",
              " ('▁all', 751),\n",
              " ('▁של', 752),\n",
              " ('ke', 753),\n",
              " ('\",', 754),\n",
              " ('°', 755),\n",
              " ('▁tak', 756),\n",
              " ('ने', 757),\n",
              " ('▁bu', 758),\n",
              " ('▁bo', 759),\n",
              " ('▁zu', 760),\n",
              " ('ą', 761),\n",
              " ('ή', 762),\n",
              " ('▁pour', 763),\n",
              " ('▁Le', 764),\n",
              " ('[', 765),\n",
              " ('▁ت', 766),\n",
              " ('▁ter', 767),\n",
              " ('▁با', 768),\n",
              " ('ci', 769),\n",
              " ('▁és', 770),\n",
              " ('co', 771),\n",
              " ('▁your', 772),\n",
              " ('om', 773),\n",
              " ('▁9', 774),\n",
              " ('▁کے', 775),\n",
              " ('▁not', 776),\n",
              " ('их', 777),\n",
              " ('▁к', 778),\n",
              " ('▁din', 779),\n",
              " ('im', 780),\n",
              " ('q', 781),\n",
              " ('ă', 782),\n",
              " ('▁have', 783),\n",
              " ('▁mai', 784),\n",
              " ('▁{', 785),\n",
              " ('▁pre', 786),\n",
              " ('▁we', 787),\n",
              " ('▁Re', 788),\n",
              " ('▁El', 789),\n",
              " ('▁he', 790),\n",
              " ('ς', 791),\n",
              " ('▁•', 792),\n",
              " ('và', 793),\n",
              " ('Y', 794),\n",
              " ('▁von', 795),\n",
              " ('▁là', 796),\n",
              " ('ې', 797),\n",
              " ('▁ar', 798),\n",
              " ('▁16', 799),\n",
              " ('▁las', 800),\n",
              " ('ú', 801),\n",
              " ('app', 802),\n",
              " ('▁کی', 803),\n",
              " ('▁au', 804),\n",
              " ('▁при', 805),\n",
              " ('U', 806),\n",
              " ('th', 807),\n",
              " ('▁}', 808),\n",
              " ('▁2014', 809),\n",
              " ('▁ba', 810),\n",
              " ('be', 811),\n",
              " ('▁18', 812),\n",
              " ('X', 813),\n",
              " ('▁2015', 814),\n",
              " ('▁2013', 815),\n",
              " ('▁(1)', 816),\n",
              " ('ой', 817),\n",
              " ('▁14', 818),\n",
              " ('▁qu', 819),\n",
              " ('ِ', 820),\n",
              " ('ha', 821),\n",
              " ('▁می', 822),\n",
              " ('man', 823),\n",
              " ('▁met', 824),\n",
              " ('are', 825),\n",
              " ('▁nga', 826),\n",
              " ('▁das', 827),\n",
              " ('▁της', 828),\n",
              " ('‘', 829),\n",
              " ('▁है', 830),\n",
              " ('ية', 831),\n",
              " ('то', 832),\n",
              " ('ь', 833),\n",
              " ('va', 834),\n",
              " ('ba', 835),\n",
              " ('】', 836),\n",
              " ('▁bi', 837),\n",
              " ('日', 838),\n",
              " ('한', 839),\n",
              " ('▁24', 840),\n",
              " ('ر', 841),\n",
              " ('ى', 842),\n",
              " ('▁est', 843),\n",
              " ('▁में', 844),\n",
              " ('lar', 845),\n",
              " ('▁2012', 846),\n",
              " ('▁dengan', 847),\n",
              " ('年', 848),\n",
              " ('▁13', 849),\n",
              " ('▁με', 850),\n",
              " ('▁untuk', 851),\n",
              " ('▁Y', 852),\n",
              " (');', 853),\n",
              " ('▁ini', 854),\n",
              " ('▁ש', 855),\n",
              " ('▁ist', 856),\n",
              " ('ve', 857),\n",
              " ('▁ا', 858),\n",
              " ('▁im', 859),\n",
              " ('this', 860),\n",
              " ('est', 861),\n",
              " ('▁online', 862),\n",
              " ('न', 863),\n",
              " ('▁А', 864),\n",
              " ('▁sur', 865),\n",
              " ('J', 866),\n",
              " ('▁У', 867),\n",
              " ('ך', 868),\n",
              " ('은', 869),\n",
              " ('ado', 870),\n",
              " ('▁ti', 871),\n",
              " ('ہ', 872),\n",
              " ('에', 873),\n",
              " ('ri', 874),\n",
              " ('▁för', 875),\n",
              " ('tu', 876),\n",
              " ('▁25', 877),\n",
              " ('lo', 878),\n",
              " ('」', 879),\n",
              " ('den', 880),\n",
              " ('%', 881),\n",
              " ('▁א', 882),\n",
              " ('د', 883),\n",
              " ('▁את', 884),\n",
              " ('▁có', 885),\n",
              " ('▁pas', 886),\n",
              " ('=\"', 887),\n",
              " ('▁ein', 888),\n",
              " ('ou', 889),\n",
              " ('▁mu', 890),\n",
              " ('月', 891),\n",
              " ('▁что', 892),\n",
              " ('ого', 893),\n",
              " ('*', 894),\n",
              " ('ի', 895),\n",
              " ('ים', 896),\n",
              " ('р', 897),\n",
              " ('▁will', 898),\n",
              " ('▁fa', 899),\n",
              " ('net', 900),\n",
              " ('▁για', 901),\n",
              " ('д', 902),\n",
              " ('ê', 903),\n",
              " ('▁*', 904),\n",
              " ('ُ', 905),\n",
              " ('ada', 906),\n",
              " ('▁qui', 907),\n",
              " ('ới', 908),\n",
              " ('г', 909),\n",
              " ('▁over', 910),\n",
              " ('▁17', 911),\n",
              " ('▁από', 912),\n",
              " ('ها', 913),\n",
              " (',\"', 914),\n",
              " ('ā', 915),\n",
              " ('▁را', 916),\n",
              " ('▁со', 917),\n",
              " ('та', 918),\n",
              " ('▁ser', 919),\n",
              " ('л', 920),\n",
              " ('que', 921),\n",
              " ('▁так', 922),\n",
              " ('▁про', 923),\n",
              " ('ể', 924),\n",
              " ('ok', 925),\n",
              " ('▁To', 926),\n",
              " ('▁σ', 927),\n",
              " ('▁და', 928),\n",
              " ('가', 929),\n",
              " ('ό', 930),\n",
              " ('ción', 931),\n",
              " ('ak', 932),\n",
              " ('ị', 933),\n",
              " ('▁که', 934),\n",
              " ('▁non', 935),\n",
              " ('ן', 936),\n",
              " ('▁је', 937),\n",
              " ('ro', 938),\n",
              " ('「', 939),\n",
              " ('ag', 940),\n",
              " ('ان', 941),\n",
              " ('على', 942),\n",
              " ('▁आ', 943),\n",
              " ('ите', 944),\n",
              " ('да', 945),\n",
              " ('с', 946),\n",
              " ('▁się', 947),\n",
              " ('▁€', 948),\n",
              " ('▁mo', 949),\n",
              " ('▁است', 950),\n",
              " ('▁·', 951),\n",
              " ('ý', 952),\n",
              " ('▁این', 953),\n",
              " ('Р', 954),\n",
              " ('▁if', 955),\n",
              " ('▁für', 956),\n",
              " ('не', 957),\n",
              " ('▁como', 958),\n",
              " ('▁X', 959),\n",
              " ('▁ca', 960),\n",
              " ('▁är', 961),\n",
              " ('ní', 962),\n",
              " ('▁19', 963),\n",
              " ('▁co', 964),\n",
              " ('▁כ', 965),\n",
              " ('▁100', 966),\n",
              " ('ere', 967),\n",
              " ('▁að', 968),\n",
              " ('wa', 969),\n",
              " ('▁cho', 970),\n",
              " ('▁voor', 971),\n",
              " ('▁2020', 972),\n",
              " ('▁میں', 973),\n",
              " ('و', 974),\n",
              " ('▁की', 975),\n",
              " ('ji', 976),\n",
              " ('▁Đ', 977),\n",
              " ('も', 978),\n",
              " ('▁pri', 979),\n",
              " ('▁este', 980),\n",
              " ('▁2011', 981),\n",
              " ('▁ce', 982),\n",
              " ('▁О', 983),\n",
              " ('▁է', 984),\n",
              " ('ik', 985),\n",
              " ('ት', 986),\n",
              " ('▁21', 987),\n",
              " ('는', 988),\n",
              " ('ку', 989),\n",
              " ('ж', 990),\n",
              " ('ے', 991),\n",
              " ('▁во', 992),\n",
              " ('ç', 993),\n",
              " ('ে', 994),\n",
              " ('п', 995),\n",
              " ('र', 996),\n",
              " ('Z', 997),\n",
              " ('▁од', 998),\n",
              " ('▁ob', 999),\n",
              " ...]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sorted(tokenizer.vocab.items(), key=lambda x: x[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "190e8c89",
      "metadata": {
        "scrolled": true,
        "id": "190e8c89",
        "outputId": "52788b38-7fb1-4e2c-f036-fcf6a988eada",
        "colab": {
          "referenced_widgets": [
            "03cc5b27eacd4bd39c91aef7a084e487"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No config specified, defaulting to: alt/alt-parallel\n",
            "Found cached dataset alt (C:/Users/MSI/.cache/huggingface/datasets/alt/alt-parallel/1.0.0/b498af66d7e1b78d98b7557e7b0b06ae54fc60491dccdc1a0f8316e677d1ce75)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03cc5b27eacd4bd39c91aef7a084e487",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Source: https://huggingface.co/datasets/alt\n",
        "dataset = load_dataset('alt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0804c019",
      "metadata": {
        "id": "0804c019"
      },
      "outputs": [],
      "source": [
        "train_dataset = dataset['train']\n",
        "test_dataset = dataset['test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15f97ace",
      "metadata": {
        "id": "15f97ace",
        "outputId": "8ddec21d-ead3-48de-9159-bc063c60ce18"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'SNT.URLID': '80188',\n",
              " 'SNT.URLID.SNTID': '1',\n",
              " 'url': 'http://en.wikinews.org/wiki/2007_Rugby_World_Cup:_Italy_31_-_5_Portugal',\n",
              " 'translation': {'bg': 'ফ্রান্সের প্যারিসের পার্ক দি প্রিন্সেস-এ হওয়া ২০০৭-এর রাগবি বিশ্বকাপের পুল সি-তে ইটালি পর্তুগালকে ৩১-৫ গোলে হারিয়েছে।',\n",
              "  'en': 'Italy have defeated Portugal 31-5 in Pool C of the 2007 Rugby World Cup at Parc des Princes, Paris, France.',\n",
              "  'en_tok': 'Italy have defeated Portugal 31-5 in Pool C of the 2007 Rugby World Cup at Parc des Princes , Paris , France .',\n",
              "  'fil': 'Natalo ng Italya ang Portugal sa puntos na 31-5 sa Grupong C noong 2007 sa Pandaigdigang laro ng Ragbi sa Parc des Princes, Paris, France.',\n",
              "  'hi': '2007 में फ़्रांस, पेरिस के पार्क डेस प्रिंसेस में हुए रग्बी विश्व कप के पूल C में इटली ने पुर्तगाल को 31-5 से हराया।',\n",
              "  'id': 'Italia berhasil mengalahkan Portugal 31-5 di grup C dalam Piala Dunia Rugby 2007 di Parc des Princes, Paris, Perancis.',\n",
              "  'ja': 'フランスのパリ、パルク・デ・プランスで行われた2007年ラグビーワールドカップのプールCで、イタリアは31対5でポルトガルを下した。',\n",
              "  'khm': 'អ៊ីតាលីបានឈ្នះលើព័រទុយហ្គាល់ 31-5 ក្នុងប៉ូលCនៃពីធីប្រកួតពានរង្វាន់ពិភពលោកនៃកីឡាបាល់ឱបឆ្នាំ2007ដែលប្រព្រឹត្តនៅប៉ាសឌេសប្រីន ក្រុងប៉ារីស បារាំង។',\n",
              "  'lo': 'ອິຕາລີໄດ້ເສຍໃຫ້ປ໊ອກຕຸຍການ 31 ຕໍ່ 5 ໃນພູລ C ຂອງ ການແຂ່ງຂັນຣັກບີ້ລະດັບໂລກປີ 2007 ທີ່ ປາກເດແພຣັງ ປາຣີ ປະເທດຝຣັ່ງ.',\n",
              "  'ms': 'Itali telah mengalahkan Portugal 31-5 dalam Pool C pada Piala Dunia Ragbi 2007 di Parc des Princes, Paris, Perancis.',\n",
              "  'my': 'ပြင်သစ်နိုင်ငံ ပါရီမြို့ ပါ့ဒက်စ် ပရင့်စက် ၌ ၂၀၀၇ခုနှစ် ရပ်ဘီ ကမ္ဘာ့ ဖလား တွင် အီတလီ သည် ပေါ်တူဂီ ကို ၃၁-၅ ဂိုး ဖြင့် ရေကူးကန် စီ တွင် ရှုံးနိမ့်သွားပါသည် ။',\n",
              "  'th': 'อิตาลีได้เอาชนะโปรตุเกสด้วยคะแนน31ต่อ5 ในกลุ่มc ของการแข่งขันรักบี้เวิลด์คัพปี2007 ที่สนามปาร์กเดแพร็งส์ ที่กรุงปารีส ประเทศฝรั่งเศส',\n",
              "  'vi': 'Ý đã đánh bại Bồ Đào Nha với tỉ số 31-5 ở Bảng C Giải vô địch Rugby thế giới 2007 tại Parc des Princes, Pari, Pháp.',\n",
              "  'zh': '意大利在法国巴黎王子公园体育场举办的2007年橄榄球世界杯C组以31-5击败葡萄牙。'}}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c42fb43",
      "metadata": {
        "id": "8c42fb43"
      },
      "outputs": [],
      "source": [
        "LANG_TOKEN_MAPPING = {\n",
        "    'zh':'<en>',\n",
        "    'bg':'<bg>',\n",
        "    'hi':'<hi>'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb392076",
      "metadata": {
        "id": "cb392076",
        "outputId": "37a2d92c-2cd4-4b7d-f543-5027d2115dbe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Embedding(250103, 512)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "special_tokens_dict = {'additional_special_tokens': list(LANG_TOKEN_MAPPING.values())}\n",
        "tokenizer.add_special_tokens(special_tokens_dict)\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d1a5851",
      "metadata": {
        "id": "5d1a5851",
        "outputId": "e1e2d914-3b7d-42d2-a31e-6d1637f85ba8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1494,  339, 1627,  259,  262, 2978,  259,  272, 1982, 1315,  260,    1,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0]])\n",
            "['▁This', '▁is', '▁just', '▁', 'a', '▁test', '▁', 'n', 'bu', 'ig', '.', '</s>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n"
          ]
        }
      ],
      "source": [
        "token_ids = tokenizer.encode(\n",
        "    example_input_str, return_tensors='pt', padding='max_length',\n",
        "    truncation=True, max_length=max_seq_len)\n",
        "print(token_ids)\n",
        "\n",
        "tokens = tokenizer.convert_ids_to_tokens(token_ids[0])\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82442571",
      "metadata": {
        "id": "82442571"
      },
      "outputs": [],
      "source": [
        "def encode_input_str(text, target_lang, tokenizer, seq_len,\n",
        "                     lang_token_map=LANG_TOKEN_MAPPING):\n",
        "  target_lang_token = lang_token_map[target_lang]\n",
        "\n",
        "  # Tokenize and add special tokens\n",
        "  input_ids = tokenizer.encode(\n",
        "      text = target_lang_token + text,\n",
        "      return_tensors = 'pt',\n",
        "      padding = 'max_length',\n",
        "      truncation = True,\n",
        "      max_length = seq_len)\n",
        "\n",
        "  return input_ids[0]\n",
        "\n",
        "def encode_target_str(text, tokenizer, seq_len,\n",
        "                      lang_token_map=LANG_TOKEN_MAPPING):\n",
        "  token_ids = tokenizer.encode(\n",
        "      text = text,\n",
        "      return_tensors = 'pt',\n",
        "      padding = 'max_length',\n",
        "      truncation = True,\n",
        "      max_length = seq_len)\n",
        "\n",
        "  return token_ids[0]\n",
        "\n",
        "def format_translation_data(translations, lang_token_map,\n",
        "                            tokenizer, seq_len=128):\n",
        "  # Choose a random 2 languages for in i/o\n",
        "  langs = list(lang_token_map.keys())\n",
        "  input_lang, target_lang = np.random.choice(langs, size=2, replace=False)\n",
        "\n",
        "  # Get the translations for the batch\n",
        "  input_text = translations[input_lang]\n",
        "  target_text = translations[target_lang]\n",
        "\n",
        "  if input_text is None or target_text is None:\n",
        "    return None\n",
        "\n",
        "  input_token_ids = encode_input_str(\n",
        "      input_text, target_lang, tokenizer, seq_len, lang_token_map)\n",
        "\n",
        "  target_token_ids = encode_target_str(\n",
        "      target_text, tokenizer, seq_len, lang_token_map)\n",
        "\n",
        "  return input_token_ids, target_token_ids\n",
        "\n",
        "def transform_batch(batch, lang_token_map, tokenizer):\n",
        "  inputs = []\n",
        "  targets = []\n",
        "  for translation_set in batch['translation']:\n",
        "    formatted_data = format_translation_data(\n",
        "        translation_set, lang_token_map, tokenizer, max_seq_len)\n",
        "\n",
        "    if formatted_data is None:\n",
        "      continue\n",
        "\n",
        "    input_ids, target_ids = formatted_data\n",
        "    inputs.append(input_ids.unsqueeze(0))\n",
        "    targets.append(target_ids.unsqueeze(0))\n",
        "\n",
        "  batch_input_ids = torch.cat(inputs).cpu()\n",
        "  batch_target_ids = torch.cat(targets).cpu()\n",
        "\n",
        "  return batch_input_ids, batch_target_ids\n",
        "\n",
        "def get_data_generator(dataset, lang_token_map, tokenizer, batch_size=32):\n",
        "  dataset = dataset.shuffle()\n",
        "  for i in range(0, len(dataset), batch_size):\n",
        "    raw_batch = dataset[i:i+batch_size]\n",
        "    yield transform_batch(raw_batch, lang_token_map, tokenizer)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02568621",
      "metadata": {
        "id": "02568621",
        "outputId": "ab1945f2-f873-474d-afb9-929e28097163"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<hi> ▁ 意大利 在 法国 巴黎 王子 公园 体育 场 举办 的 2007 年 橄 榄 球 世界杯 C 组 以 3 1-5 击 败 葡萄 牙 。 </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "▁2007 ▁में ▁फ़ ्रा ंस , ▁पे रिस ▁के ▁पार् क ▁डे स ▁ प्रि ंस ेस ▁में ▁हु ए ▁ र ग् बी ▁विश्व ▁कप ▁के ▁पू ल ▁C ▁में ▁ इट ली ▁ने ▁पुर् त गाल ▁को ▁3 1-5 ▁से ▁हर ाया । </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "Input shape: torch.Size([8, 20])\n",
            "Output shape: torch.Size([8, 20])\n"
          ]
        }
      ],
      "source": [
        "# Testing `data_transform`\n",
        "in_ids, out_ids = format_translation_data(\n",
        "    train_dataset[0]['translation'], LANG_TOKEN_MAPPING, tokenizer)\n",
        "\n",
        "print(' '.join(tokenizer.convert_ids_to_tokens(in_ids)))\n",
        "print(' '.join(tokenizer.convert_ids_to_tokens(out_ids)))\n",
        "\n",
        "# Testing data generator\n",
        "data_gen = get_data_generator(train_dataset, LANG_TOKEN_MAPPING, tokenizer, 8)\n",
        "data_batch = next(data_gen)\n",
        "print('Input shape:', data_batch[0].shape)\n",
        "print('Output shape:', data_batch[1].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98057f9c",
      "metadata": {
        "id": "98057f9c"
      },
      "outputs": [],
      "source": [
        "# model.load_state_dict(torch.load(model_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aacecdaf",
      "metadata": {
        "id": "aacecdaf"
      },
      "outputs": [],
      "source": [
        "n_epochs = 3\n",
        "batch_size = 16\n",
        "print_freq = 50\n",
        "lr = 5e-4\n",
        "n_batches = int(np.ceil(len(train_dataset) / batch_size))\n",
        "total_steps = n_epochs * n_batches\n",
        "n_warmup_steps = int(total_steps * 0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb0f9823",
      "metadata": {
        "id": "fb0f9823",
        "outputId": "f1cc16c0-c5c6-49b0-823f-600fd99108b3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\MSI\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=lr)\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer, n_warmup_steps, total_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4869451b",
      "metadata": {
        "id": "4869451b"
      },
      "outputs": [],
      "source": [
        "losses = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ef9cff9",
      "metadata": {
        "id": "0ef9cff9"
      },
      "outputs": [],
      "source": [
        "def eval_model(model, gdataset, max_iters=8):\n",
        "  test_generator = get_data_generator(gdataset, LANG_TOKEN_MAPPING,\n",
        "                                      tokenizer, batch_size)\n",
        "  eval_losses = []\n",
        "  for i, (input_batch, label_batch) in enumerate(test_generator):\n",
        "    if i >= max_iters:\n",
        "      break\n",
        "\n",
        "    model_out = model.forward(\n",
        "        input_ids = input_batch,\n",
        "        labels = label_batch)\n",
        "    eval_losses.append(model_out.loss.item())\n",
        "\n",
        "  return np.mean(eval_losses)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "013550f9",
      "metadata": {
        "id": "013550f9"
      },
      "outputs": [],
      "source": [
        "test_loss = eval_model(model, test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d896988",
      "metadata": {
        "id": "3d896988",
        "outputId": "a5ca7a1b-5dd7-432c-c06a-84cded5e4ff7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "26.336649417877197"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9509f91b",
      "metadata": {
        "scrolled": false,
        "id": "9509f91b",
        "outputId": "97cc178c-9035-483a-df32-a010fb1383c8",
        "colab": {
          "referenced_widgets": [
            "63059cba92e34505b5e8087e1245fcd7",
            "44f232080b09468c8d722fe31a54c5b4",
            "3d333b214edc4a42a33b849cdf3a1a80"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_10188\\4134151420.py:7: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  in tqdm_notebook(enumerate(data_generator), total=n_batches):\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63059cba92e34505b5e8087e1245fcd7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1131 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 | Step: 50 | Avg. loss: 11.617 | lr: 0.0004974702380952382\n",
            "Epoch: 1 | Step: 100 | Avg. loss: 5.534 | lr: 0.0004900297619047619\n",
            "Epoch: 1 | Step: 150 | Avg. loss: 4.638 | lr: 0.00048258928571428574\n",
            "Epoch: 1 | Step: 200 | Avg. loss: 4.233 | lr: 0.00047514880952380953\n",
            "Epoch: 1 | Step: 250 | Avg. loss: 4.079 | lr: 0.0004677083333333333\n",
            "Epoch: 1 | Step: 300 | Avg. loss: 3.973 | lr: 0.0004602678571428571\n",
            "Epoch: 1 | Step: 350 | Avg. loss: 3.784 | lr: 0.00045282738095238096\n",
            "Epoch: 1 | Step: 400 | Avg. loss: 3.697 | lr: 0.0004453869047619048\n",
            "Epoch: 1 | Step: 450 | Avg. loss: 3.557 | lr: 0.0004379464285714286\n",
            "Epoch: 1 | Step: 500 | Avg. loss: 3.545 | lr: 0.0004305059523809524\n",
            "Epoch: 1 | Step: 550 | Avg. loss: 3.458 | lr: 0.0004230654761904762\n",
            "Epoch: 1 | Step: 600 | Avg. loss: 3.514 | lr: 0.00041562500000000003\n",
            "Epoch: 1 | Step: 650 | Avg. loss: 3.410 | lr: 0.0004081845238095238\n",
            "Epoch: 1 | Step: 700 | Avg. loss: 3.429 | lr: 0.00040074404761904767\n",
            "Epoch: 1 | Step: 750 | Avg. loss: 3.282 | lr: 0.0003933035714285714\n",
            "Epoch: 1 | Step: 800 | Avg. loss: 3.303 | lr: 0.00038586309523809526\n",
            "Epoch: 1 | Step: 850 | Avg. loss: 3.299 | lr: 0.00037842261904761905\n",
            "Epoch: 1 | Step: 900 | Avg. loss: 3.288 | lr: 0.0003709821428571429\n",
            "Epoch: 1 | Step: 950 | Avg. loss: 3.286 | lr: 0.00036354166666666664\n",
            "Epoch: 1 | Step: 1000 | Avg. loss: 3.254 | lr: 0.0003561011904761905\n",
            "Epoch: 1 | Step: 1050 | Avg. loss: 3.240 | lr: 0.0003486607142857143\n",
            "Epoch: 1 | Step: 1100 | Avg. loss: 3.240 | lr: 0.0003412202380952381\n",
            "Test loss of 3.282\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "44f232080b09468c8d722fe31a54c5b4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1131 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 2 | Step: 50 | Avg. loss: 3.124 | lr: 0.0003291666666666667\n",
            "Epoch: 2 | Step: 100 | Avg. loss: 3.112 | lr: 0.00032172619047619053\n",
            "Epoch: 2 | Step: 150 | Avg. loss: 3.097 | lr: 0.00031428571428571427\n",
            "Epoch: 2 | Step: 200 | Avg. loss: 3.077 | lr: 0.0003068452380952381\n",
            "Epoch: 2 | Step: 250 | Avg. loss: 3.115 | lr: 0.0002994047619047619\n",
            "Epoch: 2 | Step: 300 | Avg. loss: 3.082 | lr: 0.00029196428571428575\n",
            "Epoch: 2 | Step: 350 | Avg. loss: 3.036 | lr: 0.00028452380952380954\n",
            "Epoch: 2 | Step: 400 | Avg. loss: 3.129 | lr: 0.00027708333333333334\n",
            "Epoch: 2 | Step: 450 | Avg. loss: 3.022 | lr: 0.00026964285714285713\n",
            "Epoch: 2 | Step: 500 | Avg. loss: 3.037 | lr: 0.000262202380952381\n",
            "Epoch: 2 | Step: 550 | Avg. loss: 3.002 | lr: 0.00025476190476190477\n",
            "Epoch: 2 | Step: 600 | Avg. loss: 3.075 | lr: 0.00024732142857142856\n",
            "Epoch: 2 | Step: 650 | Avg. loss: 2.966 | lr: 0.00023988095238095238\n",
            "Epoch: 2 | Step: 700 | Avg. loss: 3.055 | lr: 0.0002324404761904762\n",
            "Epoch: 2 | Step: 750 | Avg. loss: 2.973 | lr: 0.00022500000000000002\n",
            "Epoch: 2 | Step: 800 | Avg. loss: 3.008 | lr: 0.0002175595238095238\n",
            "Epoch: 2 | Step: 850 | Avg. loss: 3.005 | lr: 0.00021011904761904763\n",
            "Epoch: 2 | Step: 900 | Avg. loss: 3.058 | lr: 0.00020267857142857143\n",
            "Epoch: 2 | Step: 950 | Avg. loss: 2.968 | lr: 0.00019523809523809525\n",
            "Epoch: 2 | Step: 1000 | Avg. loss: 3.051 | lr: 0.00018779761904761904\n",
            "Epoch: 2 | Step: 1050 | Avg. loss: 2.983 | lr: 0.00018035714285714286\n",
            "Epoch: 2 | Step: 1100 | Avg. loss: 2.962 | lr: 0.00017291666666666668\n",
            "Test loss of 3.122\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3d333b214edc4a42a33b849cdf3a1a80",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1131 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 3 | Step: 50 | Avg. loss: 2.843 | lr: 0.00016086309523809526\n",
            "Epoch: 3 | Step: 100 | Avg. loss: 2.935 | lr: 0.00015342261904761906\n",
            "Epoch: 3 | Step: 150 | Avg. loss: 2.853 | lr: 0.00014598214285714288\n",
            "Epoch: 3 | Step: 200 | Avg. loss: 2.856 | lr: 0.00013854166666666667\n",
            "Epoch: 3 | Step: 250 | Avg. loss: 2.906 | lr: 0.0001311011904761905\n",
            "Epoch: 3 | Step: 300 | Avg. loss: 2.889 | lr: 0.00012366071428571428\n",
            "Epoch: 3 | Step: 350 | Avg. loss: 2.927 | lr: 0.0001162202380952381\n",
            "Epoch: 3 | Step: 400 | Avg. loss: 2.871 | lr: 0.0001087797619047619\n",
            "Epoch: 3 | Step: 450 | Avg. loss: 2.873 | lr: 0.00010133928571428571\n",
            "Epoch: 3 | Step: 500 | Avg. loss: 2.853 | lr: 9.389880952380952e-05\n",
            "Epoch: 3 | Step: 550 | Avg. loss: 2.881 | lr: 8.645833333333334e-05\n",
            "Epoch: 3 | Step: 600 | Avg. loss: 2.734 | lr: 7.901785714285714e-05\n",
            "Epoch: 3 | Step: 650 | Avg. loss: 2.864 | lr: 7.157738095238095e-05\n",
            "Epoch: 3 | Step: 700 | Avg. loss: 2.867 | lr: 6.413690476190476e-05\n",
            "Epoch: 3 | Step: 750 | Avg. loss: 2.919 | lr: 5.669642857142857e-05\n",
            "Epoch: 3 | Step: 800 | Avg. loss: 2.829 | lr: 4.925595238095238e-05\n",
            "Epoch: 3 | Step: 850 | Avg. loss: 2.842 | lr: 4.181547619047619e-05\n",
            "Epoch: 3 | Step: 900 | Avg. loss: 2.830 | lr: 3.4375e-05\n",
            "Epoch: 3 | Step: 950 | Avg. loss: 2.838 | lr: 2.693452380952381e-05\n",
            "Epoch: 3 | Step: 1000 | Avg. loss: 2.874 | lr: 1.949404761904762e-05\n",
            "Epoch: 3 | Step: 1050 | Avg. loss: 2.879 | lr: 1.2053571428571429e-05\n",
            "Epoch: 3 | Step: 1100 | Avg. loss: 2.845 | lr: 4.6130952380952385e-06\n",
            "Test loss of 3.069\n"
          ]
        }
      ],
      "source": [
        "for epoch_idx in range(n_epochs):\n",
        "  # Randomize data order\n",
        "  data_generator = get_data_generator(train_dataset, LANG_TOKEN_MAPPING,\n",
        "                                      tokenizer, batch_size)\n",
        "\n",
        "  for batch_idx, (input_batch, label_batch) \\\n",
        "      in tqdm_notebook(enumerate(data_generator), total=n_batches):\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass\n",
        "    model_out = model.forward(\n",
        "        input_ids = input_batch,\n",
        "        labels = label_batch)\n",
        "\n",
        "    loss = model_out.loss\n",
        "    losses.append(loss.item())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "\n",
        "    # Print training update info\n",
        "    if (batch_idx + 1) % print_freq == 0:\n",
        "      avg_loss = np.mean(losses[-print_freq:])\n",
        "      print('Epoch: {} | Step: {} | Avg. loss: {:.3f} | lr: {}'.format(\n",
        "          epoch_idx+1, batch_idx+1, avg_loss, scheduler.get_last_lr()[0]))\n",
        "\n",
        "  test_loss = eval_model(model, test_dataset)\n",
        "  print('Test loss of {:.3f}'.format(test_loss))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33ff8c72",
      "metadata": {
        "id": "33ff8c72"
      },
      "source": [
        "## Manual Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b22dde92",
      "metadata": {
        "id": "b22dde92",
        "outputId": "d850a9ec-d9a7-4ee1-f4fe-015c99ba844d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "saved_model_filepath = \"Saved Model/Translator_Bn_Zh.pth\"\n",
        "\n",
        "torch.save(model.state_dict(), saved_model_filepath)\n",
        "# Load the saved best model state_dict()\n",
        "model.load_state_dict(torch.load(saved_model_filepath))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3821e8ae",
      "metadata": {
        "id": "3821e8ae",
        "outputId": "73bf8ca3-f74c-450c-e8f1-b7120d2325a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Raw input text: 我喜欢学中文\n",
            "Truncated input text: <bg> 我喜欢学中文</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
          ]
        }
      ],
      "source": [
        "# test_sentence = test_dataset[2]['translation']['zh']\n",
        "test_sentence = \"我喜欢学中文\"\n",
        "print('Raw input text:', test_sentence)\n",
        "\n",
        "input_ids = encode_input_str(\n",
        "    text = test_sentence,\n",
        "    target_lang = 'bg',\n",
        "    tokenizer = tokenizer,\n",
        "    seq_len = model.config.max_length,\n",
        "    lang_token_map = LANG_TOKEN_MAPPING)\n",
        "input_ids = input_ids.unsqueeze(0).cpu()\n",
        "\n",
        "print('Truncated input text:', tokenizer.convert_tokens_to_string(\n",
        "    tokenizer.convert_ids_to_tokens(input_ids[0])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a55f4d8",
      "metadata": {
        "id": "2a55f4d8",
        "outputId": "cb577198-8ba5-471b-9659-b57ee757410e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "আমি খুব ভালো বলেছি যে, আমি ভালো বলেছি যে আমি\n",
            "আমি খুব ভালো বলেছি যে, আমি ভালো বলেছি যে, \n",
            "আমি খুব ভালো বলেছি যে, আমি ইংরেজি ভাষা\n"
          ]
        }
      ],
      "source": [
        "output_tokens = model.generate(input_ids, num_beams=10, num_return_sequences=3)\n",
        "# print(output_tokens)\n",
        "for token_set in output_tokens:\n",
        "  print(tokenizer.decode(token_set, skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38e57265",
      "metadata": {
        "id": "38e57265"
      },
      "source": [
        "## TEST OUTPUT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4e919a7",
      "metadata": {
        "id": "b4e919a7",
        "outputId": "aa82d7d4-04cf-47ea-cdf3-3d2ab86713e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "我是学生  ->  उन्होंने यह भी बताया कि मैंने अपने विद्यार्थियों के \n"
          ]
        }
      ],
      "source": [
        "\n",
        "input_text = '' # {type:\"string\"}\n",
        "output_language = 'hi' # [\"bg\", \"hi\", \"zh\"]\n",
        "\n",
        "\n",
        "input_ids = encode_input_str(\n",
        "    text = input_text,\n",
        "    target_lang = output_language,\n",
        "    tokenizer = tokenizer,\n",
        "    seq_len = model.config.max_length,\n",
        "    lang_token_map = LANG_TOKEN_MAPPING)\n",
        "input_ids = input_ids.unsqueeze(0).cpu()\n",
        "\n",
        "output_tokens = model.generate(input_ids, num_beams=20, length_penalty=0.2)\n",
        "print(input_text + '  ->  ' + \\\n",
        "      tokenizer.decode(output_tokens[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22c9a4fc",
      "metadata": {
        "id": "22c9a4fc"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce0c180c",
      "metadata": {
        "id": "ce0c180c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f97fd98",
      "metadata": {
        "id": "4f97fd98"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b72cd807",
      "metadata": {
        "id": "b72cd807"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}